# config file for snakemake
# adjust variables berfore running baseDmux workflow

##############################
##### input/output directory
INDIR: "test/reads" ## absolute path to a single folder holding 'ONT runs folders'. Each of those contains fast5 files stored in a 'fast5' folder
OUTDIR: "test/results" ## absolute path to output directory
NASID: "" # host name, if indir and outdir in NAS but workdir is not


##############################
##### kit and flowcell
KIT: "SQK-RBK004"
FLOWCELL: "FLO-MIN106"


##############################
##### resources
RESOURCE: "CPU" # "CPU"/"GPU" ## resources for running Guppy and Deepbinner
NUM_GPUS: 4 # mumber of GPU devices to use # baseDmux will decide CUDA devices based on availability ## GPU mode only


##############################
##### guppy_basecaller + fast5_subset parameters
RULE_GUPPY_BASECALLING:
    'MIN_QSCORE': 7 # basecalling will filter reads based on minimum q-score specified here
    'NUM_CALLERS': 8 # number of parallel basecallers to create ## recommended: NUM_CALLERS=2*NUM_GPUS
    'CPU_THREADS_PER_CALLER': 12 # number of CPU threads to create for each caller to use
    'GPU_RUNNERS_PER_DEVICE': 4 # number of neural network runners to create per CUDA device ## GPU mode only
    'ADDITION': "--calib_detect --chunks_per_caller 10000" # additional params that do not affect output format ## provide parameters with arguments ## do NOT use --compress_fastq, because next steps use uncompressed fastq
    'KEEP_LOG_FILES': False # True/False, whether to keep guppy log files or not
    'KEEP_FAIL_READS': False # True/False, whether to keep failed reads or not
    'FAST5_COMPRESSION': "gzip" # "vbz"/"vbz_legacy_v0"/"gzip" ## compression algorithm by fast5_subset (ont_fast5_api) to reduce file size and improve read/write performance


##############################
##### choose types of demultiplexer
DEMULTIPLEXER: ["guppy", "deepbinner"] # "guppy"/"deepbinner", leave `[]` if you do not want demultiplexing


##############################
##### guppy_barcoder parameters
RULE_GUPPY_DEMULTIPLEXING:
    'CONFIG': "configuration.cfg" # "a configuration file, which contains details of the barcoding arrangements to attempt to detect"
    'WORKER_THREADS': 12 # the number of worker threads to spawn for the barcoder to use
    'ADDITION': "--trim_barcodes" # additional parameters of guppy_barcoder


##############################
##### multi_to_single_fast5 (ont_fast5_api) parameters
RULE_MULTI_TO_SINGLE_FAST5:
    'THREADS': 12


##############################
##### deepbinner classify parameters
RULE_DEEPBINNER_CLASSIFICATION:
    'PRESET': "rapid" # 'native'/'rapid', `--preset`
    'OMP_NUM_THREADS': 12 # number of threads to use, `--omp_num_threads`
    'ADDITION': "" # additional arguments for `deepbinner classify`


##############################
##### MinIONQC parameters for basecall results and demultiplex results
RULE_MINIONQC:
    'PROCESSORS': 12 # number of threads to use
    'ADDITION': "-s FALSE" # additional parameters

##############################
##### Filtering tools and parameters
READS_FILTERING: [porechop, filtlong1, filtlong2, filtlong3]
# if porechop is called here, it will run once only, after get_reads_per_genome and will be taken as input of any filtlong runs if specified.
# multiple filtlong runs with different parameters are enable. Name of the runs can be customized by the user, as long as they have a "filtlong" prefix. Parameters for each run must be specified individually under exactly the same key name.
# for the moment, porechop and filtlong are only available if get_reads_per_genome is called. (will be improve soon so that it can run after basecalling if rule get_reads_per_genome is off.)

porechop:
    'THREADS': 8
    'PARAMS': "--discard_middle"

filtlong1:
    'PARAMS': "--min_length 1000 --target_bases 500000000 --keep_percent 90"

filtlong2:
    'PARAMS': "--min_length 1000 --target_bases 500000000 --keep_percent 90 --mean_q_weight 10"

filtlong3:
    'PARAMS': "--min_length 1000 --target_bases 500000000 --keep_percent 90 --length_weight 10"

##############################
##### get_reads_per_genome parameters
RULE_GET_READS_PER_GENOME:
    'BARCODE_BY_GENOME': ""
    # Information table for subseting fast5 and fastq to genome folder
    # if "guppy" or "deepbinner" is specified in "Demultiplexer" on the table, this demultiplexer will be used
    # for demultiplexing even though it is specified in the value of 'DEMULTIPLEXER'.
    # Values in the `Genome_ID` column must be UNIQUE for each row
    # if BARCODE_BY_GENOME is left blank this rule will not be executed and reads belonging to individual barcodes will not be grouped in 'genome' bins#
    'FASTQ_TRANSFERING': "copy" # "copy"/"move"
    'GET_FAST5': False # True/False, whether to get and group together reads in fast5 files per genome
    'MAX_THREADS': 2 # maximum number of threads available for fast5 subset. the number of threads actually used will be automatically adjusted based on the number of fast5 inputs for each genome, but not higher than MAX_THREADS


##############################
##### reports
REPORTS:
    'SNAKEMAKE_REPORT':  # do you want to include the resuls of these rules in the snakemake report? warning: they can make the report file become very big in size
        'MINIONQC_BASECALL': True # minionqc plots (11 plots/run)
        'MINIONQC_DEMULTIPLEX': False # minionqc plots (11 plots/barcode)
        'MULTIQC_BASECALL': True # link to multiqc html report
        'MULTIQC_DEMULTIPLEX': True # link to multiqc report

    'DEMULTIPLEX_REPORT': True # do you want to create a "collective" report for all the results of demultiplex and filtering?
    'DEMULTIPLEX_REPORT_THREADS': 6 # Number of parallel cores to use for the rule generating the custom report.
